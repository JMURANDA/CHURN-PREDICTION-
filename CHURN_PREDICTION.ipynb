{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing PySpark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXEPAI77QjI9",
        "outputId": "126f00fb-35f2-4083-f569-b2fdacfe8295"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=252e9f4f028246e54dc155afc9d0babd6c6699fb2c5de4539bd9d64b711bd687\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, GBTClassifier, LinearSVC\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "0Ya_nZUvQl-l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a SparkSession\n",
        "spark = SparkSession.builder.appName(\"TelecomChurnPrediction\").getOrCreate()\n",
        "# Loading  the dataset\n",
        "dataset = spark.read.csv(\"/content/telecom_dataset (1).csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Data Preprocessing\n",
        "dataset = dataset.dropna()  # Drop rows with missing values"
      ],
      "metadata": {
        "id": "AxvfcRtQQzNy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating call duration (assuming call_start_time and call_end_time columns are present)\n",
        "dataset = dataset.withColumn(\"call_duration\", (col(\"TotalCharges\") - col(\"MonthlyCharges\")) / 60)\n",
        "\n",
        "# Calculating average monthly spend\n",
        "dataset = dataset.withColumn(\"average_monthly_spend\", col(\"MonthlyCharges\"))"
      ],
      "metadata": {
        "id": "aqYGGljTQ_TR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s_R3XrdaRjvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encodinging categorical variables\n",
        "categorical_cols = ['Contract', 'Churn','Gender']\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col+'_index').fit(dataset) for col in categorical_cols]\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "dataset = pipeline.fit(dataset).transform(dataset)\n",
        "# Feature scaling\n",
        "assembler = VectorAssembler(inputCols=['Age', 'average_monthly_spend', 'call_duration', 'Gender_index'], outputCol='features')\n",
        "dataset = assembler.transform(dataset)\n",
        "\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
        "scaler_model = scaler.fit(dataset)\n",
        "dataset = scaler_model.transform(dataset)"
      ],
      "metadata": {
        "id": "qOp8PIumSFM3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing sets\n",
        "(train_data, test_data) = dataset.randomSplit([0.8, 0.2], seed=42)\n",
        "# Model training and evaluation\n",
        "lr = LogisticRegression(labelCol='Churn_index', featuresCol='scaled_features')\n",
        "\n",
        "# Model selection and training\n",
        "classifiers = [\n",
        "    LogisticRegression(labelCol='Churn_index', featuresCol='scaled_features'),\n",
        "    RandomForestClassifier(labelCol='Churn_index', featuresCol='scaled_features'),\n",
        "    GBTClassifier(labelCol='Churn_index', featuresCol='scaled_features'),\n",
        "    LinearSVC(labelCol='Churn_index', featuresCol='scaled_features')\n",
        "]"
      ],
      "metadata": {
        "id": "lbS4-hjDSQxM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ylj4H5RkQJg0"
      },
      "outputs": [],
      "source": [
        "# Defining the parameter grid for each classifier\n",
        "paramGrids = [\n",
        "    ParamGridBuilder()\n",
        "        .addGrid(LogisticRegression.regParam, [0.1, 0.01])\n",
        "        .addGrid(LogisticRegression.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "        .build(),\n",
        "    ParamGridBuilder()\n",
        "        .addGrid(RandomForestClassifier.numTrees, [10, 20, 30])\n",
        "        .addGrid(RandomForestClassifier.featureSubsetStrategy, ['auto', 'sqrt'])\n",
        "        .build(),\n",
        "    ParamGridBuilder()\n",
        "        .addGrid(GBTClassifier.maxDepth, [5, 10])\n",
        "        .addGrid(GBTClassifier.maxIter, [20, 30])\n",
        "        .build(),\n",
        "    ParamGridBuilder()\n",
        "        .addGrid(LinearSVC.maxIter, [10, 20])\n",
        "        .addGrid(LinearSVC.regParam, [0.1, 0.01])\n",
        "        .build()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = BinaryClassificationEvaluator(labelCol='Churn_index')\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Iterating over classifiers and parameter grids\n",
        "for classifier, paramGrid in zip(classifiers, paramGrids):\n",
        "    pipeline = Pipeline(stages=[classifier])\n",
        "    crossval = CrossValidator(estimator=pipeline,\n",
        "                              estimatorParamMaps=paramGrid,\n",
        "                              evaluator=evaluator,\n",
        "                              numFolds=5)\n",
        "    cv_model = crossval.fit(train_data)"
      ],
      "metadata": {
        "id": "txjBM-XZTHog"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation on test data\n",
        "predictions = cv_model.transform(test_data)\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Accuracy for {classifier.__class__.__name__}: {accuracy}\")\n",
        "\n",
        "if accuracy > best_accuracy:\n",
        "        best_model = cv_model.bestModel\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2IIViwjTRmS",
        "outputId": "76ec8351-6257-48d4-c24e-33cc6ac747c8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for LinearSVC: 0.2285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the best model and its parameters\n",
        "print(\"Best Model:\")\n",
        "print(best_model.stages[0])\n",
        "\n",
        "# Use the best model for predictions\n",
        "best_predictions = best_model.transform(test_data)\n",
        "\n",
        "# Performing evaluation on the best model\n",
        "best_accuracy = evaluator.evaluate(best_predictions)\n",
        "print(\"Best Model in Terms of Accuracy:\", best_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMtiXNDJTqDu",
        "outputId": "99883410-c172-46c0-cbf9-825262219617"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model:\n",
            "LinearSVCModel: uid=LinearSVC_bd86d0035d18, numClasses=2, numFeatures=4\n",
            "Best Model in Terms of Accuracy: 0.2285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='Churn_index', predictionCol='prediction')\n",
        "\n",
        "# Evaluating the best model on test data\n",
        "accuracy = evaluator.evaluate(best_predictions, {evaluator.metricName: 'accuracy'})\n",
        "precision = evaluator.evaluate(best_predictions, {evaluator.metricName: 'weightedPrecision'})\n",
        "recall = evaluator.evaluate(best_predictions, {evaluator.metricName: 'weightedRecall'})\n",
        "f1_score = evaluator.evaluate(best_predictions, {evaluator.metricName: 'f1'})"
      ],
      "metadata": {
        "id": "roMPjKWEUFni"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8R4a1UxT0Cb",
        "outputId": "965905bc-3916-4287-ebc9-ee5dab48fb63"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4\n",
            "Precision: 0.16\n",
            "Recall: 0.4\n",
            "F1-Score: 0.2285714285714286\n"
          ]
        }
      ]
    }
  ]
}